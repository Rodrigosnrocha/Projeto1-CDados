{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Rodrigo Santos Neves Rocha\r\n",
    "\r\n",
    "Nome: Pietro Zanga Neto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import nltk\r\n",
    "nltk.download('rslp')\r\n",
    "stemmer = nltk.stem.RSLPStemmer()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Rsngamer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Rsngamer\\Documents\\Jupyter Notebook\\CDados\\Projeto 1\\github\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "filename = 'Tesla.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dados_train = pd.read_excel(filename, sheet_name='Treinamento')\r\n",
    "dados_test= pd.read_excel(filename,sheet_name='Teste')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\r\n",
    "\r\n",
    "O produto escolhido se refere à marca de automóveis Tesla, produtora de veículos elétricos. Os tweets foram classificados como relevantes ou irrelevantes a partir de certos requisitos:\r\n",
    "1. O tweet se refere a um automóvel Tesla diretamente(ex. \"joão comprou um Tesla Model X novo ontem\")\r\n",
    "2. O tweet se refere à empresa Tesla Motors(ex. \"comprei ações da Tesla outro dia\")\r\n",
    "3. O tweet não se refere exclusivamente a Nikola Tesla ou seus feitos(ex. \"quero montar uma bobina de Tesla\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def cleanup(tweet):\r\n",
    "    for palavra in tweet:\r\n",
    "        if '@' in palavra or 'https' in palavra or \"&amp\" in palavra or \"&gt\" in palavra:\r\n",
    "            tweet.replace(palavra,\"\")\r\n",
    "\r\n",
    "    #tweet = tweet.replace(\"\", \"\")    TEMPLATE\r\n",
    "    tweet = tweet.replace(\" '\", \"\")\r\n",
    "    tweet = tweet.replace(\"' \", \"\")\r\n",
    "    tweet = tweet.replace(\"#\", \"\")\r\n",
    "    tweet = tweet.replace(\"!\", \" \")\r\n",
    "    tweet = tweet.replace(\"?\", \" \")\r\n",
    "    tweet = tweet.replace(\"(\", \" \")\r\n",
    "    tweet = tweet.replace(\")\", \" \")\r\n",
    "    tweet = tweet.replace(\" rt \", \" \")\r\n",
    "    tweet = tweet.replace(\"rt \", \" \")\r\n",
    "    tweet = tweet.replace(\"¥\", \"\")\r\n",
    "    tweet = tweet.replace(\"%\", \"\")\r\n",
    "    tweet = tweet.replace(\"}\", \"\")\r\n",
    "    tweet = tweet.replace(\"{\", \"\")\r\n",
    "    tweet = tweet.replace(\"|\", \"\")\r\n",
    "    tweet = tweet.replace(\"\\\\\", \"\")\r\n",
    "    tweet = tweet.replace(\"/\", \"\")\r\n",
    "    tweet = tweet.replace(\"&\", \"\")\r\n",
    "    tweet = tweet.replace(\";\", \"\")\r\n",
    "    tweet = tweet.replace(\"£\", \"\")\r\n",
    "    tweet = tweet.replace(\"€\", \"\")\r\n",
    "    tweet = tweet.replace(\"•\", \"\")\r\n",
    "    tweet = tweet.replace(\"*\", \"\")\r\n",
    "    tweet = tweet.replace(\"=\", \"\")\r\n",
    "    tweet = tweet.replace(\"~\", \"\")\r\n",
    "    tweet = tweet.replace(\"\", \"\")\r\n",
    "\r\n",
    "    tweet = tweet.lower()\r\n",
    "    tweet = tweet.split()\r\n",
    "    \r\n",
    "    clean_tweet = []\r\n",
    "    for palavra in tweet:\r\n",
    "        clean_tweet.append(stemmer.stem(palavra))\r\n",
    "\r\n",
    "    return clean_tweet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "total_relevante = dados_train['Treinamento'][dados_train['Relevante'] == 0].count()\r\n",
    "total_irrelevante = dados_train['Treinamento'][dados_train['Relevante'] == 1].count()\r\n",
    "\r\n",
    "total = total_relevante + total_irrelevante\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "palavras_relevantes = []\r\n",
    "palavras_irrelevantes = []\r\n",
    "\r\n",
    "frequencia_relevantes = {}\r\n",
    "frequencia_irrelevantes = {}\r\n",
    "\r\n",
    "n_relevante = 0\r\n",
    "n_irrelevante = 0\r\n",
    "\r\n",
    "i = 0\r\n",
    "for relevancia in dados_train['Relevante']:\r\n",
    "    clean_tweet = cleanup(dados_train['Treinamento'][i])\r\n",
    "    for palavra in clean_tweet:\r\n",
    "        if relevancia == 1:\r\n",
    "            if palavra not in palavras_irrelevantes:\r\n",
    "                palavras_irrelevantes.append(palavra)\r\n",
    "                frequencia_irrelevantes[palavra] = 1\r\n",
    "            else:\r\n",
    "                frequencia_irrelevantes[palavra] += 1\r\n",
    "            n_irrelevante += 1\r\n",
    "            \r\n",
    "        else:\r\n",
    "            if palavra not in palavras_relevantes:\r\n",
    "                palavras_relevantes.append(palavra)\r\n",
    "                frequencia_relevantes[palavra] = 1\r\n",
    "            else:\r\n",
    "                frequencia_relevantes[palavra] += 1\r\n",
    "            n_relevante += 1\r\n",
    "            \r\n",
    "    i += 1\r\n",
    "    \r\n",
    "n_total = n_relevante + n_irrelevante"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def p_compara(p_0, p_1):\r\n",
    "    if p_0 > p_1:\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def p_calc(tweet, palavras, n_palavras):\r\n",
    "    prob = 0\r\n",
    "    total = n_palavras\r\n",
    "    tweet_limpo = cleanup(tweet)\r\n",
    "    for palavra in tweet_limpo:\r\n",
    "        frequencia = 1\r\n",
    "        if palavra in palavras:\r\n",
    "            frequencia += palavras[palavra]\r\n",
    "        prob += frequencia/(total + n_total)\r\n",
    "    return prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "lista_previsao = []\r\n",
    "for tweet in dados_test['Teste']:\r\n",
    "    prob_1 = p_calc(tweet, frequencia_irrelevantes, n_irrelevante)\r\n",
    "    prob_0 = p_calc(tweet, frequencia_relevantes, n_relevante)\r\n",
    "    lista_previsao.append(p_compara(prob_0, prob_1))\r\n",
    "\r\n",
    "dados_test['Previsão'] = lista_previsao"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "acertos = 0\r\n",
    "indice = 0\r\n",
    "for avaliacao in dados_test['Relevante']:\r\n",
    "    if avaliacao == dados_test['Previsão'][indice]:\r\n",
    "        acertos += 1\r\n",
    "    indice += 1\r\n",
    "\r\n",
    "proporcao_acertos = acertos/len(dados_test)\r\n",
    "porcentagem_acertos = proporcao_acertos*100\r\n",
    "print(f\"Acertos: {acertos}\")\r\n",
    "print(len(dados_test))\r\n",
    "print(128/200)\r\n",
    "print(f\"Classificações corretas(porcentagem): {porcentagem_acertos:.2f}%\")    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acertos: 128\n",
      "200\n",
      "0.64\n",
      "Classificações corretas(porcentagem): 64.00%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "c8731b49693dc5968e6ddbab57736ef9ac925c713cbf398b25511c79d73a9c65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}